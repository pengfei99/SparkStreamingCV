{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from PIL import Image\n",
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "\n",
    "from pyspark.sql.types import StringType, ArrayType, BooleanType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup the input, output path for image and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_input_folder_path = \"/tmp/sparkcv/input/\"\n",
    "cascade_model_path = \"/mnt/hgfs/Centos7_share_folder/trained_models\"\n",
    "cascade_model_name = \"haarcascade_frontalface_default.xml\"\n",
    "faces_output_path = \"/tmp/sparkcv/output/faces/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"StreamingExample\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.8.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Read raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "query_list=spark.streams.active\n",
    "    \n",
    "print(query_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_schema = spark.read.format(\"binaryFile\").load(image_input_folder_path).schema\n",
    "raw_image_df_stream = spark.readStream.format(\"binaryFile\").option(\"pathGlobFilter\", \"*.png\") \\\n",
    "        .schema(image_schema) \\\n",
    "        .load(image_input_folder_path)\n",
    "stream = raw_image_df_stream.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .trigger(processingTime='2 seconds') \\\n",
    "    .queryName(\"raw_image_df_stream\") \\\n",
    "    .start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Waiting for next trigger',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+\n",
      "|                path|   modificationTime|length|             content|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "|file:/tmp/sparkcv...|2020-05-22 07:19:34|787983|[89 50 4E 47 0D 0...|\n",
      "|file:/tmp/sparkcv...|2020-05-22 07:19:28|206029|[89 50 4E 47 0D 0...|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, clear_output,Image\n",
    "\n",
    "# Image(filename='test.png') \n",
    "while stream.isActive:\n",
    "    clear_output(wait=True)\n",
    "    display(stream.status)\n",
    "    display(spark.sql('SELECT * FROM raw_image_df_stream').show())\n",
    "    time.sleep(10)\n",
    "stream.awaitTermination(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image_df_stream.stop()\n",
    "stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_name(path):\n",
    "    return f.substring_index(path, \"/\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def face_extraction(image_name):\n",
    "\n",
    "    image_path = image_input_folder_path + image_name\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n",
    "    face_model = cv2.CascadeClassifier(\"{}/{}\".format(cascade_model_path,cascade_model_name))\n",
    "    faces = face_model.detectMultiScale(img, scaleFactor=1.1, minNeighbors=4)  # returns a list of (x,y,w,h) tuples\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Extract faces from the origin image\n",
    "    extracted_face_list = []\n",
    "    for i in range(len(faces)):\n",
    "        (x, y, w, h) = faces[i]\n",
    "        crop = img[y:y + h, x:x + w]\n",
    "        extracted_face_img_name = image_name[:-4] + \"_x\" + str(x) + \"_y\" + str(y) + \"_w\" + str(\n",
    "            w) + \"_h\" + str(h) + \".png\"\n",
    "        extracted_face_list.append(extracted_face_img_name)\n",
    "        extracted_face_output_path = faces_output_path + extracted_face_img_name\n",
    "        cv2.imwrite(extracted_face_output_path, crop)\n",
    "\n",
    "    return extracted_face_list\n",
    "\n",
    "Face_Extraction_UDF = f.udf(lambda image_name: face_extraction(image_name), ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def detect_faces_streaming(raw_image_df_stream):\n",
    "    # get the image name df\n",
    "    image_name_df = raw_image_df_stream.select(\"path\") \\\n",
    "        .withColumn(\"origin_image_name\", extract_file_name(f.col(\"path\"))).drop(\"path\")\n",
    "\n",
    "    # run the face detection function on each row\n",
    "    detected_face_list_df = image_name_df.withColumn(\"detected_face_list\", Face_Extraction_UDF(\"origin_image_name\"))\n",
    "    detected_face_df = detected_face_list_df.withColumn(\"extracted_face_image_name\",\n",
    "                                                        f.explode(f.col(\"detected_face_list\"))).drop(\n",
    "        \"detected_face_list\")\n",
    "    return detected_face_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_streaming_cv",
   "language": "python",
   "name": "spark_streaming_cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}