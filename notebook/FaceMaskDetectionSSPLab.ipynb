{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from PIL import Image\n",
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "from pyspark.sql.types import StringType, ArrayType, BooleanType\n",
    "from IPython.display import display, clear_output,Image\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup the input, output path for image and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Key': 'pengfei/tmp/spark-history',\n",
       " 'name': 'pengfei/tmp/spark-history',\n",
       " 'type': 'directory',\n",
       " 'Size': 0,\n",
       " 'size': 0,\n",
       " 'StorageClass': 'DIRECTORY'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = \"https://\"+os.environ['AWS_S3_ENDPOINT']\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': endpoint})\n",
    "\n",
    "# Set up model path\n",
    "model_path=\"s3a://pengfei/diffusion/computer_vision/trained_model\"\n",
    "fs.info(model_path)\n",
    "cascade_model_path = model_path\n",
    "vgg19_model_path = model_path\n",
    "cascade_model_name = \"haarcascade_frontalface_default.xml\"\n",
    "vgg19_model_name = \"masknet.h5\"\n",
    "\n",
    "#### Modify, you need to change the bucket_name to your own minio bucket name\n",
    "bucket_name=\"pengfei\"\n",
    "\n",
    "\n",
    "check_point_path=\"{}/tmp/checkpoint\".format(bucket_name)\n",
    "fs.touch('s3a://'+check_point_path+'/.keep')\n",
    "fs.info(check_point_path)\n",
    "\n",
    "faces_output_path=\"s3a://{}/tmp/sparkcv/output/faces\".format(bucket_name)\n",
    "fs.touch(faces_output_path+'/.keep')\n",
    "fs.info(faces_output_path)\n",
    "\n",
    "final_output_path = \"s3a://{}/tmp/sparkcv/output/final\".format(bucket_name)\n",
    "fs.touch(final_output_path+'/.keep')\n",
    "fs.info(final_output_path)\n",
    "\n",
    "image_input_folder_path=\"s3a://{}/tmp/sparkcv/input\".format(bucket_name)\n",
    "fs.touch(image_input_folder_path+'/.keep')\n",
    "fs.info(image_input_folder_path)\n",
    "\n",
    "event_log_path=\"{}/tmp/spark-history\".format(bucket_name)\n",
    "fs.touch('s3://'+event_log_path+'/.keep')\n",
    "fs.info(event_log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder.master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "    .appName(\"Evaluate data format\") \\\n",
    "    .config(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:master\") \\\n",
    "    .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT']) \\\n",
    "    .config(\"spark.executor.instances\", \"5\") \\\n",
    "    .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE']) \\\n",
    "    .config(\"spark.eventLog.enabled\",\"true\") \\\n",
    "    .config(\"spark.eventLog.dir\",\"s3a://\"+event_log_path) \\\n",
    "    .config(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.8.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                   READY   STATUS      RESTARTS   AGE\n",
      "deleting-pods-with-completed-status-1622538000-2bpcr   0/1     Completed   0          5m18s\n",
      "jupyter-1622533988-5599d5bb49-jxkj6                    1/1     Running     0          72m\n",
      "mlflow-deployment-dd54d6c6b-xnglp                      1/1     Running     0          42d\n",
      "mlflow-model-deployment-869dd96bbf-f7mgs               1/1     Running     0          11d\n",
      "postgres-1616502799-67f86f5bdf-wfgjx                   1/1     Running     0          69d\n",
      "ubuntu-1616490233-56d6684bb4-trwqt                     1/1     Running     2          70d\n"
     ]
    }
   ],
   "source": [
    "! kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 face extraction spark udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_extraction(image_name):\n",
    "    image_path = image_input_folder_path + image_name\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n",
    "    face_model = cv2.CascadeClassifier(\"{}/{}\".format(cascade_model_path,cascade_model_name))\n",
    "    faces = face_model.detectMultiScale(img, scaleFactor=1.1, minNeighbors=4)  # returns a list of (x,y,w,h) tuples\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Extract faces from the origin image\n",
    "    extracted_face_list = []\n",
    "    for i in range(len(faces)):\n",
    "        (x, y, w, h) = faces[i]\n",
    "        crop = img[y:y + h, x:x + w]\n",
    "        extracted_face_img_name = image_name[:-4] + \"_x\" + str(x) + \"_y\" + str(y) + \"_w\" + str(\n",
    "            w) + \"_h\" + str(h) + \".png\"\n",
    "        extracted_face_list.append(extracted_face_img_name)\n",
    "        extracted_face_output_path = \"{}/{}\".format(faces_output_path, extracted_face_img_name)\n",
    "        cv2.imwrite(extracted_face_output_path, crop)\n",
    "\n",
    "    return extracted_face_list\n",
    "\n",
    "Face_Extraction_UDF = f.udf(lambda image_name: face_extraction(image_name), ArrayType(StringType()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1.2 column function for extract image name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_name(path):\n",
    "    return f.substring_index(path, \"/\", -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1.3 mask detection spark udf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function use a pre-trained vgg19 model to predict if it has mask or no. It returns true, if it has mask.\n",
    "def face_mask_prediction(face_image_name):\n",
    "    # read raw face image\n",
    "    img = cv2.imread(\"{}/{}\".format(faces_output_path, face_image_name))\n",
    "    # normalize the raw image for vgg19 model\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "    img = np.reshape(img, [1, 128, 128, 3])\n",
    "    img = img / 255.0\n",
    "    vgg19_model = tf.keras.models.load_model(\"{}/{}\".format(vgg19_model_path, vgg19_model_name))\n",
    "    score = vgg19_model.predict(img)\n",
    "    if np.argmax(score) == 0:\n",
    "        res = True\n",
    "    else:\n",
    "        res = False\n",
    "    # print(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "Face_Mask_Prediction_UDF = f.udf(lambda face_image_name: face_mask_prediction(face_image_name), BooleanType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1.4 get face position in origin image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_coordinate_of_origin_image(face_image_name):\n",
    "    x = face_image_name.split(\"_\")[1][1:]\n",
    "    y = face_image_name.split(\"_\")[2][1:]\n",
    "    w = face_image_name.split(\"_\")[3][1:]\n",
    "    h = face_image_name.split(\"_\")[4][1:].split('.')[0]\n",
    "    return int(x), int(y), int(w), int(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1.5 prediction integration spark udf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def integrate_face_mask_prediction(face_image_name, origin_image_name, has_mask):\n",
    "    # check if the image is already treated or not, if yes, it means it has multiple faces. and we just add new mask\n",
    "    # prediction to untreated faces.\n",
    "    # If not treated, we load image from\n",
    "    treated_image_path = \"{}/{}\".format(final_output_path, origin_image_name)\n",
    "    # If the image is treated, update the treated image\n",
    "    if os.path.isfile(treated_image_path):\n",
    "        image = cv2.imread(treated_image_path)\n",
    "    else:\n",
    "        # Get the untreated image from input\n",
    "        image = cv2.imread(\"{}/{}\".format(image_input_folder_path, origin_image_name))\n",
    "\n",
    "    # set Label text\n",
    "    if has_mask:\n",
    "        mask_label = \"MASK\"\n",
    "    else:\n",
    "        mask_label = \"NO MASK\"\n",
    "    # Get the coordinate and size of face image\n",
    "    (x, y, w, h) = get_face_coordinate_of_origin_image(face_image_name)\n",
    "\n",
    "    # Set text color for mask label\n",
    "    mask_label_color = {\"MASK\": (0, 255, 0), \"NO MASK\": (0, 0, 255)}\n",
    "\n",
    "    # Insert mask label to image\n",
    "    image = cv2.putText(image, mask_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                        mask_label_color[mask_label], 2)\n",
    "    # Insert a rectangle around the face\n",
    "    image = cv2.rectangle(image, (x, y), (x + w, y + h), mask_label_color[mask_label], 1)\n",
    "    # Save the image\n",
    "    cv2.imwrite(treated_image_path, image)\n",
    "\n",
    "    return \"Done\"\n",
    "\n",
    "\n",
    "Integrate_Face_Mask_Prediction_UDF = f.udf(\n",
    "    lambda face_image_name, origin_image_name, has_mask: integrate_face_mask_prediction(face_image_name,\n",
    "                                                                                        origin_image_name, has_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1.6 render image in jupyter notebook\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_image(image_folder_path, image_list):\n",
    "    for image_name in image_list:\n",
    "        image_path = \"{}/{}\".format(image_folder_path,image_name)\n",
    "        display(Image(filename=image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Process image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if everyone wears a face mask or not in an image, we will follow the below steps:\n",
    "1. Read raw image\n",
    "2. Detect faces from the raw image, output extracted faces as single images(haar-cascade)\n",
    "3. Use a pre-trained vgg19 model to check if a mask is worn\n",
    "4. Integrate prediction as tags on origin image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Read raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_schema = spark.read.format(\"binaryFile\").load(image_input_folder_path).schema\n",
    "raw_image_df_stream = spark.readStream \\\n",
    "    .format(\"binaryFile\") \\\n",
    "    .schema(image_schema) \\\n",
    "    .option(\"maxFilesPerTrigger\", \"500\") \\\n",
    "    .option(\"recursiveFileLookup\", \"true\") \\\n",
    "    .option(\"pathGlobFilter\", \"*.png\") \\\n",
    "    .load(image_input_folder_path) \\\n",
    "    .withColumn(\"time_stamp\", f.current_timestamp())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 Detect faces and output extracted each face as a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the image name df\n",
    "image_name_df = raw_image_df_stream \\\n",
    "    .select(\"path\",\"time_stamp\") \\\n",
    "    .withColumn(\"origin_image_name\", extract_file_name(f.col(\"path\"))) \\\n",
    "    .drop(\"path\")\n",
    "\n",
    "# run the face detection function on each row\n",
    "detected_face_list_df = image_name_df.withColumn(\"detected_face_list\", Face_Extraction_UDF(\"origin_image_name\"))\n",
    "\n",
    "detected_face_df = detected_face_list_df \\\n",
    "                   .withColumn(\"extracted_face_image_name\",f.explode(f.col(\"detected_face_list\")))\\\n",
    "                   .drop(\"detected_face_list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.3 predict if the face wear mask or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predict_mask_df_stream = detected_face_df.withColumn(\"has_mask\",\n",
    "                                                    Face_Mask_Prediction_UDF(\"extracted_face_image_name\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.4: Integrate faces with tag to origin image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "complete_df_stream = predict_mask_df_stream.withColumn(\"integration\",\n",
    "                                                Integrate_Face_Mask_Prediction_UDF(\"extracted_face_image_name\",\n",
    "                                                                                   \"origin_image_name\",\n",
    "                                                                                   \"has_mask\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. View the output data frame and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stream = complete_df_stream.withWatermark(\"time_stamp\", \"10 seconds\") \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"raw_image_df_stream\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Terminated with exception: Writing job aborted.',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in range(20):\n",
    "    clear_output(wait=True)\n",
    "    display(stream.status)\n",
    "    _df=spark.sql('SELECT * FROM raw_image_df_stream')\n",
    "    col_name=\"origin_image_name\"\n",
    "    if _df.count()>0:\n",
    "        display(_df.show(10,False))\n",
    "        img_list=_df.select(col_name).distinct().toPandas()[col_name]\n",
    "        display(img_list)\n",
    "        render_image(final_output_path,img_list)\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# stop sparksession\n",
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_streaming_cv",
   "language": "python",
   "name": "spark_streaming_cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
